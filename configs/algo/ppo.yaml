name: ppo
timesteps: 200000
learning_rate: 3.0e-4
batch_size: 2048
n_steps: 2048
gamma: 0.995
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01
n_epochs: 10
policy: MlpPolicy
policy_kwargs:
  net_arch: [256, 256]
